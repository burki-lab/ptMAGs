{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single gene trees\n",
    "\n",
    "In this notebook, we infer single gene trees with the 94 plastid genes including both the references and the plastid MAGs, with the purpose of identifying contaminants, chimeras, and cases of LGT. \n",
    "\n",
    "However, manually parsing trees to identify such cases can be difficult when the trees contain hundreds of unlabelled environmental sequences. Therefore, prior to these phylogenies, we ran a quick-and-dirty set of SGTs with IQTree. Taxa were filtered if they had low coverage (present in fewer than 10 genes), were chimeras, or were bacterial contaminants (i.e. clustered with bacteria in the trees). Following this, a concatenated tree of the 34 \"slow-genes\" of [Ševčíková et al 2015](https://doi.org/10.1038/srep10134) and [Janouškovec et al 2010](https://doi.org/10.1073/pnas.1003335107) was inferred. The concatenated tree was run in IQTREE under the LG+C40+I+G model. (These preliminary analyses are not described in these notebooks but documentation is available on request). Based on the concatenated tree, we derived the taxonomic position of the MAGs, and labelled the MAGs with the taxonomy, making it easier to parse the next round of single gene trees and spot any aberrant sequences.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if python is 3.10.5\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import __init__\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we store the important data paths in PATH_FILE\n",
    "PATH_FILE = \"../../PATHS.json\"\n",
    "\n",
    "paths_dict = json.load(open(PATH_FILE, \"r\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect homologs\n",
    "\n",
    "Step 1 is extracting the 68 (+28) gene sequences from each MAG using BLAST. As query, we will use reference sequences [collected in the previous step](01_refs_SGTs.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Put query (reference) sequences in working_dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directory containing reference sequences\n",
    "REF = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF']['FINAL']\n",
    "\n",
    "## Output folder where we copy the reference sequences\n",
    "WORKING_DATASET = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['REF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$FINAL\" \"$WORKING_DATASET\"\n",
    "\n",
    "cp \"$1\"/*fasta \"$2\"/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create blast databases for all ptMAG proteomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder containing proteomes of the ptMAGs\n",
    "PROTEOMES = paths_dict['ANALYSIS_DATA']['PLASTOMES']['MFANNOTATIONS']['PROTEOMES']\n",
    "\n",
    "## Output folder that will contain the blast dbs of the ptMAGs\n",
    "TO_ADD = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['TOADD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROTEOMES\" \"$TO_ADD\"\n",
    "\n",
    "## load the blast module on Uppmax\n",
    "module load bioinfo-tools\n",
    "module load blast\n",
    "\n",
    "for i in \"$1\"/*fasta; do\n",
    "    mag=$(basename $i | cut -f 1 -d '.')\n",
    "    makeblastdb -in $i -dbtype prot -out \"$2\"/\"$mag\".db\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Blast references against the blast databases\n",
    "\n",
    "We first create a text file called `blastdb_name.txt` with the names of the blast databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TO_ADD\"\n",
    "\n",
    "for i in \"$1\"/*; do\n",
    "    echo $i | \\\n",
    "    cut -f 1 -d '.' | \\\n",
    "    sed -E 's/(.*)/\\1\\.db/'\n",
    "done | uniq > \"$1\"/blastdb_name.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder containing the reference fasta files that we will use as blast query\n",
    "WORKING_DATASET = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['REF']\n",
    "\n",
    "## Folder containing the blast dbs\n",
    "TO_ADD = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['TOADD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We submit the blast jobs now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$WORKING_DATASET\" \"$TO_ADD\" \n",
    "\n",
    "for i in  \"$1\"/*.fasta; do\n",
    "    sbatch ../../uppmax_scripts/script_bin/job_running_blast.sh \\\n",
    "        $i \"$2\"/blastdb_name.txt\n",
    "    sleep 1\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Extract best BLAST hits\n",
    "\n",
    "Blast output files are generated in the folder containing the reference query sequences. For each gene, we want to:\n",
    "- parse the blast output files, \n",
    "- extract the best hit,\n",
    "- pull out the corresponding sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full gene dataset\n",
    "JANO_FULL = paths_dict['DATABASES'][\"GENE_LISTS\"][\"JANO_FULL\"]\n",
    "\n",
    "# Genes to add\n",
    "GENES_ADD = paths_dict['DATABASES'][\"GENE_LISTS\"][\"GENES_ADD\"]\n",
    "\n",
    "## Folder containing the query fasta files and the blast outputs\n",
    "WORKING_DATASET = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['REF']\n",
    "\n",
    "## Folder containing proteomes of ptMAGs\n",
    "PROTEOMES = paths_dict['ANALYSIS_DATA']['PLASTOMES']['MFANNOTATIONS']['PROTEOMES']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first pull the best blast hit. We can do that by taking the first line of the blast output (since the blast output is already sorted). The second column of the blast tabular output contains the name of the best sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$JANO_FULL\" \"$WORKING_DATASET\"\n",
    "\n",
    "## Extract best blast hit for each gene and taxon\n",
    "cut -f 1 $1 | grep -v \"gene\" | sort -u | while read line; do\n",
    "    for i in \"$2\"/\"$line\".fasta__*; do\n",
    "        cat $i | head -n 1 | cut -f2 >> \"$2\"/\"$line\"_toAdd.list\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$GENES_ADD\" \"$WORKING_DATASET\"\n",
    "\n",
    "## Extract best blast hit for each gene and taxon\n",
    "cat $1 | while read line; do\n",
    "    for i in \"$2\"/\"$line\".fasta__*; do\n",
    "        cat $i | head -n 1 | cut -f2 >> \"$2\"/\"$line\"_toAdd.list\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually went through each {gene}_toAdd.list file and removed the hits that were from other genes!!! \n",
    "\n",
    "We pull the corresponding sequences now. \n",
    "\n",
    "First we concatenate all the proteomes together to make it easier to search the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROTEOMES\" \"$TO_ADD\" \n",
    "for i in \"$1\"/*fasta; do (cat \"${i}\"; echo) >> \"$2\"/all.fasta; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use [seqkit](https://github.com/shenwei356/seqkit) to pull out the sequences for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$WORKING_DATASET\" \"$TO_ADD\"\n",
    "\n",
    "for i in \"$1\"/*_toAdd.list; do\n",
    "    gene=$(basename $i | cut -f 1 -d '.')\n",
    "    seqkit grep -f $i \"$2\"/all.fasta > \"$1\"/\"$gene\".fasta\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put together the query and the extracted sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$JANO_FULL\" \"$WORKING_DATASET\"\n",
    "\n",
    "cut -f 1 $1 | grep -v \"gene\" | sort -u | while read line; do\n",
    "    cat \"$2\"/\"$line\".fasta \"$2\"/\"$line\"_toAdd.fasta > \"$2\"/\"$line\".all.fasta\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$GENES_ADD\" \"$WORKING_DATASET\"\n",
    "\n",
    "cat $1 | while read line; do\n",
    "    cat \"$2\"/\"$line\".fasta \"$2\"/\"$line\"_toAdd.fasta > \"$2\"/\"$line\".all.fasta\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the trees, we probably need to format the fasta headers so that the tree inference programme is happy. That means replacing ';' and '.' with '-'. \n",
    "\n",
    "We also edited our fasta headers so they would work with PhyloFisher (which we were originally planning to use for parsing our gene trees - however, we ended up using FigTree at the end). Since PhyloFisher expects the fasta headers to be identical across all genes for each taxon, all extra information apart from the taxon name should be after an underscore (as PhyloFisher seems to ignore everything after the underscore).\n",
    "\n",
    "Finally we also use seqkit to rename any duplicates that may exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing output fasta files\n",
    "DATASET = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['ROOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$WORKING_DATASET\" \"$DATASET\"\n",
    "\n",
    "for i in \"$1\"/*all.fasta; do\n",
    "    gene=$(basename $i | cut -f 1 -d '.')\n",
    "    cat $i | \\\n",
    "    tr '_' '-' | \\\n",
    "    tr ';' '-' | \\\n",
    "    sed -E 's/>(gene=.*-)(mag=.*)-(contig=.*)/>\\2_\\1\\3/' | \\\n",
    "    seqkit rename \\\n",
    "    > \"$2\"/\"$gene\".fasta\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Taxonomically label MAGs\n",
    "\n",
    "Here, we use the taxonomy derived from a preliminary concatenated tree of 34 genes to label each MAG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing output fasta files\n",
    "DATASET = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['ROOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DATASET\"\n",
    "\n",
    "for i in \"$1\"/*fasta\n",
    "    do cat $i | \\\n",
    "    tr '_' '\\t' | \\\n",
    "    seqkit replace -p '^(\\S+)(.+?)$' -r '{kv}$2' -k \"$1\"/mags_taxonomy.tsv --keep-key | \\\n",
    "    tr '\\t' '_' \\\n",
    "    > tmp\n",
    "    mv tmp $i\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Align, trim, and infer single gene trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Align\n",
    "\n",
    "We align the genes with mafft-ginsi using the --unalign 0.6 option to avoid over-alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gene_iterator import GeneIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with extracted gene dataset\n",
    "DATASET = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['ROOT']\n",
    "\n",
    "# Read_genes\n",
    "JANO_FULL = paths_dict['DATABASES']['GENE_LISTS']['JANO_FULL']\n",
    "genes = set(line.split()[0].strip() for line in open(JANO_FULL, \"r\"))\n",
    "\n",
    "# Read genes\n",
    "GENES_ADD = paths_dict['DATABASES'][\"GENE_LISTS\"][\"GENES_ADD\"]\n",
    "genes_add = set(line.split()[0].strip() for line in open(GENES_ADD, \"r\"))\n",
    "\n",
    "# Directory for mafft output\n",
    "MAFFT_DIR = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['ALIGNMENTS']['REF_MAGS']['MAFFT']\n",
    "\n",
    "# Slurmlog csv\n",
    "SLURMLOG = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['ALIGNMENTS']['REF_MAGS']['MAFFTLOG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(DATASET, gene_list=genes, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(DATASET, gene_list=genes_add, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.run_mafft(MAFFT_DIR, SLURMLOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long are the alignments for each gene?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$MAFFT_DIR\"\n",
    "\n",
    "seqkit stats \"$1\"/*fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Trim\n",
    "\n",
    "A number of studies (e.g. [Tan et al 2015](https://doi.org/10.1093/sysbio/syv033), [Irisarri et al 2022](https://doi.org/10.1093/sysbio/syab036)) have shown that aggressive trimming gives worse results. We therefore opted for gentle trimming with TrimAl by removing columns with 90% or more gaps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing aligned fasta files\n",
    "MAFFT_DIR = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['ALIGNMENTS']['REF_MAGS']['MAFFT']\n",
    "\n",
    "# Read_genes\n",
    "JANO_FULL = paths_dict['DATABASES']['GENE_LISTS']['JANO_FULL']\n",
    "genes = set(line.split()[0].strip() for line in open(JANO_FULL, \"r\"))\n",
    "\n",
    "# Read genes\n",
    "GENES_ADD = paths_dict['DATABASES'][\"GENE_LISTS\"][\"GENES_ADD\"]\n",
    "genes_add = set(line.split()[0].strip() for line in open(GENES_ADD, \"r\"))\n",
    "\n",
    "# Directory for trimal output\n",
    "TRIMAL_DIR = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['ALIGNMENTS']['REF_MAGS']['TRIMAL']\n",
    "\n",
    "# Slurmlog csv\n",
    "SLURMLOG = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['ALIGNMENTS']['REF_MAGS']['TRIMALLOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(MAFFT_DIR, gene_list=genes, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(MAFFT_DIR, gene_list=genes_add, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.run_trimal(TRIMAL_DIR, SLURMLOG, MAFFT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long are the alignments for each gene?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TRIMAL_DIR\"\n",
    "\n",
    "seqkit stats \"$1\"/*fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Infer trees with IQ-TREE\n",
    "\n",
    "We infer trees with [IQ-TREE](http://www.iqtree.org/) using the best fitting model for each gene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing aligned, trimmed fasta files\n",
    "TRIMAL_DIR = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['ALIGNMENTS']['REF_MAGS']['TRIMAL']\n",
    "\n",
    "# Read_genes\n",
    "JANO_FULL = paths_dict['DATABASES']['GENE_LISTS']['JANO_FULL']\n",
    "genes = set(line.split()[0].strip() for line in open(JANO_FULL, \"r\"))\n",
    "\n",
    "# Read genes\n",
    "GENES_ADD = paths_dict['DATABASES'][\"GENE_LISTS\"][\"GENES_ADD\"]\n",
    "genes_add = set(line.split()[0].strip() for line in open(GENES_ADD, \"r\"))\n",
    "\n",
    "# Directory for trees output\n",
    "TREES_DIR = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['TREES']['REF_MAGS']\n",
    "\n",
    "# Slurmlog csv\n",
    "SLURMLOG = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['TREES']['TREESLOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(TRIMAL_DIR, gene_list=genes, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(TRIMAL_DIR, gene_list=genes_add, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.run_siqtree(TREES_DIR, SLURMLOG, TRIMAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse Single Gene Trees\n",
    "We manually parsed the trees to remove duplicates and contaminants. To help us do so, we colour the tips corresponding to references and duplicates (in FigTree). \n",
    "\n",
    "The following colour scheme is used:  \n",
    "References = blue (#0000ff)  \n",
    "Red-plastid-lineage MAGs = orange (#ff8000)  \n",
    "Green-plastid-lineage MAGs = green (#00ff00)  \n",
    "Duplicates = red (#ff0000)  \n",
    "Other 'weird' artefacts (super long branches etc) = red (#ff0000)  \n",
    "Taxa filtered in the previous step = cyan (#00ffff)  \n",
    "Bacterial contaminants = purple (#800080) \n",
    "\n",
    "Changes are documented in the text file  `Notes.txt` (intermediate file, not provided)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean dataset\n",
    "\n",
    "We can now remove artefacts and duplicates from our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Extract bacterial contaminants (also referred to as paralogs here)\n",
    "\n",
    "We start by extracting all the sequences marked as bacterial origin (in purple). It is important to retain these separately as 'paralogs' so that bacterial contaminants can be easily detected if we add more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the original dataset as fasta files\n",
    "DATASET = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['ROOT']\n",
    "\n",
    "# Folder containing the parsed trees\n",
    "TREES_DIR = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['TREES']['REF_MAGS']\n",
    "\n",
    "# Output folder for paralog fasta files \n",
    "PARALOGS = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['FINAL']['PARALOGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TREES_DIR\" \"$DATASET\" \"$PARALOGS\"\n",
    "\n",
    "## For each parsed tree file, get the list of bacterial seqs\n",
    "for i in \"$1\"/*parsed.tre\n",
    "do\n",
    "    gene=$(basename $i | cut -f 1 -d '.')\n",
    "    grep \"#800080\" $i | \\\n",
    "    grep \"mag_\" | \\\n",
    "    sed -E 's/\\s+(.*)\\[\\&\\!color=#800080\\]/\\1/' | \\\n",
    "    sed -E 's/mag_/mag=/' | \\\n",
    "    sed -E 's/taxonomy_/taxonomy=/' | \\\n",
    "    sed -E 's/gene_/gene=/' | \\\n",
    "    sed -E 's/contig_/contig=/' | \\\n",
    "    sed -E 's/Filtered_/Filtered*/g' \\\n",
    "    > \"$1\"/paralogs.list\n",
    "## extract the seqs from the original dataset and output to paralog file\n",
    "    seqkit grep -f \"$1\"/paralogs.list \"$2\"/\"$gene\".fasta > \"$3\"/\"$gene\"_paralogs.fasta\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We edit the fasta headers to add the word \"paralog\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PARALOGS\"\n",
    "\n",
    "for i in \"$1\"/*fasta\n",
    "do \n",
    "    cat $i | \\\n",
    "    sed -E 's/(>.*)/\\1_paralog/' \\\n",
    "    > fasta\n",
    "    mv fasta $i\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Extract clean sequences\n",
    "\n",
    "We now extract the clean sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the original dataset as fasta files\n",
    "DATASET = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['WORKING']['ROOT']\n",
    "\n",
    "# Folder containing the parsed trees\n",
    "TREES_DIR = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['TREES']['REF_MAGS']\n",
    "\n",
    "# Output folder for clean, final, fasta files \n",
    "CLEAN = paths_dict['ANALYSIS_DATA']['SINGLE_GENE_ANALYSIS']['DATASET']['REF_MAGS']['FINAL']['CLEAN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each gene, we remove the artefacts and duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TREES_DIR\"\n",
    "\n",
    "## For each parsed tree file, get the list of artefacts and duplicates.\n",
    "for i in \"$1\"/*parsed.tre\n",
    "do\n",
    "    gene=$(basename $i | cut -f 1 -d '.')\n",
    "    echo $gene\n",
    "    egrep \"#800080|#ff0000|#00ffff\" $i | \\\n",
    "    sed -E 's/\\s+(.*)\\[\\&\\!color=.*\\]/\\1/' | \\\n",
    "    sed -E 's/mag_/mag=/' | \\\n",
    "    sed -E 's/taxonomy_/taxonomy=/' | \\\n",
    "    sed -E 's/gene_/gene=/' | \\\n",
    "    sed -E 's/contig_/contig=/' | \\\n",
    "    sed -E 's/Filtered_/Filtered*/g' | \\\n",
    "    sed -E 's/taxo_/taxo=/' | \\\n",
    "    sed -E 's/accession_/accession=/' \\\n",
    "    > \"$1\"/\"$gene\".remove.list\n",
    "    wc -l \"$1\"/\"$gene\".remove.list\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the following from each remove.list file as I had a made a mistake when assigning taxonomy.\n",
    " \n",
    "CHL-AON-Bin-218-11-c  \n",
    "CHL-AOS-Bin-120-3-c (remove only duplicate from psaA)  \n",
    "CHL-MED-Bin-373-2-c  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TREES_DIR\" \"$DATASET\" \"$CLEAN\"\n",
    "\n",
    "for i in \"$1\"/*remove.list\n",
    "do \n",
    "    gene=$(basename $i | cut -f 1 -d '.')\n",
    "    echo $gene\n",
    "    seqkit grep -f $i \"$2\"/\"$gene\".fasta -v > \"$3\"/\"$gene\".fasta\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check to see how many taxa are marked multiple times. Taxa marked more than once are likely chimeras/artefacts, and should therefore be removed from the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TREES_DIR\" \n",
    "\n",
    "cat \"$1\"/*remove.list | \\\n",
    "grep \"mag=\" | \\\n",
    "cut -f1 -d '_' | \\\n",
    "sort | \\\n",
    "uniq -c | \\\n",
    "grep \" 1 mag\" -v | \\\n",
    "sed -E 's/.*(mag.*)/\\1/' \\\n",
    "> \"$1\"/all.remove.list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97 taxa were marked multiple times. I manually checked each of these 97 taxa and looked at *why* they were marked. A few simply included in this list when I marked duplicates, and some had a long branches in a couple of gene trees, but otherwise okay. I therefore removed the following from `all.remove.list`.\n",
    "\n",
    "CHL-ARC-Bin-238-20-c  \n",
    "CHL-AOS-Bin-109-4-c  \n",
    "CHL-AOS-Bin-120-3-c  \n",
    "CHL-AON-Bin-218-11-c  \n",
    "CHL-AON-Bin-136-6-c  \n",
    "CHL-AON-Bin-136-10-c  \n",
    "CHL-ARC-Bin-238-31-c  \n",
    "CHL-ARC-Bin-270-17-c  \n",
    "CHL-ION-Bin-101-4-c  \n",
    "CHL-ION-Bin-84-8-c  \n",
    "CHL-MED-Bin-250-48-c  \n",
    "CHL-MED-Bin-373-2-c  \n",
    "CHL-PON-Bin-64-17-c  \n",
    "CHL-PSW-Bin-163-25-c  \n",
    "CHL-PSW-Bin-61-3-c  \n",
    "CHL-PSW-Bin-87-1-c  \n",
    "TARA-B110000977-METAG-scaffold-147  \n",
    "CHL-SOC-Bin-154-29-c  \n",
    "CHL-ARC-Bin-318-2-c  \n",
    "CHL-MED-Bin-250-53-c  \n",
    "CHL-PON-Bin-102-2-c  \n",
    "CHL-PSW-Bin-50-1-c  \n",
    "CHL-SOC-Bin-140-6-c  \n",
    "CHL-SOC-Bin-154-29-c\n",
    "CHL-AON-Bin-218-24-c\n",
    "CHL-SOC-Bin-140-6-c\n",
    "\n",
    "After removing, I was left with 83 taxa to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TREES_DIR\" \"$CLEAN\"\n",
    "\n",
    "for i in \"$2\"/*fasta\n",
    "do \n",
    "    seqkit grep -r -f \"$1\"/all.remove.list $i -v > fasta\n",
    "    mv fasta $i\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Rename sequences\n",
    "\n",
    "Finally we rename the sequences so that taxa share the exact same headers across different genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$CLEAN\"\n",
    "\n",
    "for i in \"$1\"/*fasta\n",
    "do \n",
    "    cat $i | cut -f1 -d '_' > fasta\n",
    "    mv fasta $i\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Ševčíková, T., Horák, A., Klimeš, V., Zbránková, V., Demir-Hilton, E., Sudek, S., ... & Eliáš, M. (2015). Updating algal evolutionary relationships through plastid genome sequencing: did alveolate plastids emerge through endosymbiosis of an ochrophyte?. Scientific reports, 5(1), 10134. https://doi.org/10.1038/srep10134\n",
    "\n",
    "Janouškovec, J., Horák, A., Oborník, M., Lukeš, J., & Keeling, P. J. (2010). A common red algal origin of the apicomplexan, dinoflagellate, and heterokont plastids. Proceedings of the National Academy of Sciences, 107(24), 10949-10954. https://doi.org/10.1073/pnas.1003335107\n",
    "\n",
    "Shen, W., Le, S., Li, Y., & Hu, F. (2016). SeqKit: a cross-platform and ultrafast toolkit for FASTA/Q file manipulation. PloS one, 11(10), e0163962. https://doi.org/10.1371/journal.pone.0163962\n",
    "\n",
    "Rambaut, A. (2009). FigTree. Tree figure drawing tool. http://tree.bio.ed.ac.uk/software/figtree/.\n",
    "\n",
    "Tice, A. K., Žihala, D., Pánek, T., Jones, R. E., Salomaki, E. D., Nenarokov, S., ... & Brown, M. W. (2021). PhyloFisher: a phylogenomic package for resolving eukaryotic relationships. PLoS Biology, 19(8), e3001365. https://doi.org/10.1371/journal.pbio.3001365"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptMAGs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
