{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mitochondrial contigs from targeted coassembly  \n",
    "\n",
    "In the search for a potential host for leptophytes, we now turn to the mitochondria. It has been difficult to recover putative nuclear genome sequences of leptophytes. One reason could be that plastid genomes seem to be more abundant/multi-copy than the corresponding nuclear genome, so it is easier to recover the plastid genome. Given that the mitochondrial genome is also expected to be at a higher abundance, we try to (1) recover mitochondrial contigs from the targeted co-assembly, (2) infer phylogenies to identify the contigs, and (3) compare distribution patterns with those of Lepto-01. Together, steps 2 and 3 could help identify putative leptophyte hosts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if python is 3.10.5\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import __init__\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we store the important data paths in PATH_FILE\n",
    "PATH_FILE = \"../../PATHS.json\"\n",
    "\n",
    "paths_dict = json.load(open(PATH_FILE, \"r\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Annotate mitochondrial contigs\n",
    "\n",
    "Tom recovered 34 complete mitochondrial contigs. I will now run mfannot (as done for the plastid contigs) to annotate the contigs and to extract protein coding genes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Run MFAnnot\n",
    "\n",
    "We use genetic code 1 (standard) or the genetic code 4 (mold mitochondrial) as appropriate (genetic code determined by Codetta). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directory with samples (SMP_DIR). Paths are defined in PATHS.json in the main directory.\n",
    "SMP_DIR = paths_dict['DATABASES'][\"COASSEMBLY\"][\"MITO\"]\n",
    "\n",
    "## Define output directory\n",
    "MFOUT_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"MASTERFILE\"]\n",
    "MFSLURM_CSV = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"MFSLURMLOG\"]\n",
    "\n",
    "## Define MFannot database\n",
    "PROTEIN_COLLECTION_DB = paths_dict[\"DATABASES\"][\"MF_ANNOT_REFS\"][\"PROTEINS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plastome_raw_data import PlastomeRawIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pri = PlastomeRawIterator(SMP_DIR, suffix=\"fa\")\n",
    "\n",
    "pri.run_mfannot(MFOUT_DIR, MFSLURM_CSV, PROTEIN_COLLECTION_DB, force=False, restart_fails=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Convert to GenBank Format\n",
    "\n",
    "We used the asn2gb tool from NCBI to convert the sqn files (files in ASN.1 syntax that contains the sequences, their features, and the metadata about submission to NCBI) to flat genbank files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directory with sqn files (SQN_DIR). Paths are defined in PATHS.json in the main directory.\n",
    "SQN_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"MASTERFILE\"]\n",
    "\n",
    "## Define output directory\n",
    "GBOUT_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"GENBANK\"]\n",
    "\n",
    "## Define slurm csv to track jobs \n",
    "MFSLURM_CSV = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"GBSLURMLOG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqn2gb import PlastomeSQNIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = PlastomeSQNIterator(SQN_DIR, GBOUT_DIR, MFSLURM_CSV)\n",
    "\n",
    "psi.run_asn2gb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Extract proteome\n",
    "\n",
    "We extract the proteome from the genbank files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directory with GenBank files\n",
    "MAG_GB = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"GENBANK\"]\n",
    "\n",
    "## Define output directory to store proteomes\n",
    "MAG_PROT = paths_dict['ANALYSIS_DATA'][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"PROTEOMES\"]\n",
    "\n",
    "## Define whether the file is a reference (from NCBI) or a MAG (opt between \"ref\" and \"mag\").\n",
    "FILE_TYPE = \"mag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gb_to_prot import mfannot_gb_prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfannot_gb_prot(MAG_GB, MAG_PROT, FILE_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Get references for phylogenies\n",
    "\n",
    "We will now infer some phylogenies to identify the mitochondrial contigs. To do so, we need a reference dataset. Here, we will start off with the 100 taxa, 93 gene from [Williamson et al 2025]( https://doi.org/10.1038/s41586-025-08709-5). This dataset will be reduced to include only eukaryotic taxa and mitochondria encoded genes. To this, we will add the rappemonad mitochondrial genome from [Kawachi et al 2021](https://www.cell.com/current-biology/fulltext/S0960-9822(21)00351-1), and seven other representatives of cryptophytes and haptophytes from [Kim et al 2018](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4626-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Get reference dataset from Williamson et al 2025\n",
    "\n",
    "I downloaded the unaligned single gene fasta files from the Figshare repo associated with Williamson et al 2025 (https://figshare.com/s/59b28ecc0056dc8d0d03), and then kept only the 40 genes that are mitochondria encoded (at least in some eukaryotes). \n",
    "\n",
    "Each single gene file contains prokaryote sequences and other eukaryote sequences that were not in the final concatenated dataset. I will retain the 61 eukaryotes in the final concatenated file of Williamson et al 2025 (without the Anaeramoebae) and remove everything else. The header names were also restricted to 10 characters, so we update the headers to include the full name and taxonomy string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fasta file directory\n",
    "REF_FASTA = paths_dict['ANALYSIS_DATA'][\"COASSEMBLY\"][\"MITO\"][\"REFS\"][\"FASTA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$REF_FASTA\"\n",
    "\n",
    "for i in \"$1\"/*fasta; do \n",
    "    echo $i\n",
    "    seqkit grep -f <(cat \"$1\"/references_taxo.list.txt | cut -f1) $i > test\n",
    "    seqkit replace -p '^(\\S+)$' -r '{kv}$2' -k \"$1\"/references_taxo.list.txt test > test2\n",
    "    mv test2 $i\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Add more haptophyte, cryptophyte, and other references\n",
    "\n",
    "We add more haptophyte and cryptophyte references as the leptophyte plastids are most closely to these groups. In total, this corresponds to 9 mitochondria:\n",
    "\n",
    "MG680941\tChroomonas placoidea  \n",
    "MG680942\tCryptomonas curvata  \n",
    "MG680945\tProteomonas sulcata  \n",
    "NC_002572\tRhodomonas salina  \n",
    "MG680943\tStoreatula species  \n",
    "MG680944\tTeleaulax amphioxeia  \n",
    "JN131834\tPhaeocystis antarctica  \n",
    "KC967226\tPhaeocystis globosa  \n",
    "LC564891\tPavlomulina ranunculiformis  \n",
    "\n",
    "A fasta file containing all the mitochondria genomes was manually downloaded using Batch Entrez (https://www.ncbi.nlm.nih.gov/sites/batchentrez). \n",
    "\n",
    "In addition, we also added mitochondria genomes from major lineages in the eukaryotic tree of life including katablepharids, centrohelids, and Microheliela. In total, these corresponded to 18 genomes from [Yazaki et al 2022](https://doi.org/10.3389/fevo.2022.1030570), [Nishimura et al 2019](https://doi.org/10.1038/s41598-019-41238-6), [Janouskovec et al 2017](https://doi.org/10.1016/j.cub.2017.10.051) and [Wideman et al 2019](https://doi.org/10.1038/s41564-019-0605-4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then split this fasta file into multiple files, with one plastid genome per file, and the file name corresponding to the sequence header. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFANNOT = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"REFS\"][\"MFANNOT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$MFANNOT\"\n",
    "\n",
    "awk '/^>/{if(N){close(N)} N=substr($1,2) \".fa\"; print > N; next;} {if(N) print >> N}' \"$1\"/sequence.fasta\n",
    "\n",
    "rm \"$1\"/sequence.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Run MFAnnot\n",
    "\n",
    "We run mfannot to annotate the sequences (so they are consistent). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directory with samples. This will also be the output directory.\n",
    "MFANNOT = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"REFS\"][\"MFANNOT\"]\n",
    "\n",
    "## Define slurmlog csv\n",
    "MFSLURM_CSV = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"REFS\"][\"MFSLURMLOG\"]\n",
    "\n",
    "## Define MFannot database\n",
    "PROTEIN_COLLECTION_DB = paths_dict[\"DATABASES\"][\"MF_ANNOT_REFS\"][\"PROTEINS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri = PlastomeRawIterator(MFANNOT, suffix=\"fa\")\n",
    "\n",
    "pri.run_mfannot(MFANNOT, MFSLURM_CSV, PROTEIN_COLLECTION_DB, force=False, restart_fails=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then convert to Genbank format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define slurm csv to track jobs \n",
    "GBSLURM_CSV = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"REFS\"][\"GBSLURMLOG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = PlastomeSQNIterator(MFANNOT, MFANNOT, GBSLURM_CSV)\n",
    "\n",
    "psi.run_asn2gb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Extract the proteome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directory with GenBank files and where poteomes will be stored.\n",
    "MFANNOT = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"REFS\"][\"MFANNOT\"]\n",
    "\n",
    "## Define whether the file is a reference (from NCBI) or a MAG (opt between \"ref\" and \"mag\").\n",
    "FILE_TYPE = \"ref\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfannot_gb_prot(MFANNOT, MFANNOT, FILE_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Collect homologs\n",
    "\n",
    "We now collect homologs of the 40 genes from both the 9 additional references as well as the 34 mitochondrial contigs extracted by Tom. We start by putting the query (references from Williamson et al 2025) sequences in a working_dataset folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Create BLAST databases for all new proteomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder containing proteomes of the ptMAGs\n",
    "MAG_PROT = paths_dict['ANALYSIS_DATA'][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"PROTEOMES\"]\n",
    "\n",
    "REF_PROT = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"REFS\"][\"MFANNOT\"]\n",
    "\n",
    "## Output folder that will contain the blast dbs of the new proteomes\n",
    "TO_ADD = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['TO_ADD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$MAG_PROT\" \"$REF_PROT\" \"$TO_ADD\"\n",
    "\n",
    "## load the blast module on Uppmax\n",
    "module load bioinfo-tools\n",
    "module load blast\n",
    "\n",
    "for i in \"$1\"/*fasta; do\n",
    "    seq=$(basename $i | cut -f 1 -d '.')\n",
    "    makeblastdb -in $i -dbtype prot -out \"$3\"/\"$seq\".db\n",
    "done\n",
    "\n",
    "for i in \"$2\"/*fasta; do\n",
    "    seq=$(basename $i | cut -f 1 -d '.')\n",
    "    makeblastdb -in $i -dbtype prot -out \"$3\"/\"$seq\".db\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. BLAST references against database\n",
    "\n",
    "We first create a text file called `blastdb_name.txt` with the names of the blast databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TO_ADD\"\n",
    "\n",
    "for i in \"$1\"/*; do\n",
    "    echo $i | \\\n",
    "    cut -f 1 -d '.' | \\\n",
    "    sed -E 's/(.*)/\\1\\.db/'\n",
    "done | uniq > \"$1\"/blastdb_name.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder containing the reference fasta files that we will use as blast query\n",
    "WORKING_DATASET = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['WORKING']\n",
    "\n",
    "## Folder containing the blast dbs\n",
    "TO_ADD = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['TO_ADD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We submit the blast jobs now! Use an evalue of 1e-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$WORKING_DATASET\" \"$TO_ADD\" \n",
    "\n",
    "for i in  \"$1\"/*.fasta; do\n",
    "    sbatch ../../uppmax_scripts/script_bin/job_running_blast.sh \\\n",
    "        $i \"$2\"/blastdb_name.txt\n",
    "    sleep 1\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Extract best BLAST hits\n",
    "\n",
    "Blast output files are generated in the folder containing the reference query sequences. For each gene, we want to:\n",
    "- parse the blast output files, \n",
    "- extract the best hit,\n",
    "- pull out the corresponding sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full gene dataset\n",
    "GENE_LIST = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['MITOGENES']\n",
    "\n",
    "## Folder containing the query fasta files and the blast outputs\n",
    "WORKING_DATASET = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['WORKING']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first pull the best blast hit. We can do that by taking the first line of the blast output (since the blast output is already sorted). The second column of the blast tabular output contains the name of the best sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$GENE_LIST\" \"$WORKING_DATASET\"\n",
    "\n",
    "## Extract best blast hit for each gene and taxon\n",
    "cat $1 | while read line; do\n",
    "    for i in \"$2\"/\"$line\".fasta__*; do\n",
    "        cat $i | head -n 1 | cut -f2 >> \"$2\"/\"$line\"_toAdd.list\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually went through each {gene}_toAdd.list file and removed the hits that were from other genes!!! For 12 genes, less than 10 hits were found, leaving just 28 genes for which hits were detected. The genes with less than 10 hits were: atp3, atp9, ccmFC, cox11, nad8, rpl11, rpl1, rpl20, rpl27, rpl31, sdh2, tufA.\n",
    "\n",
    "We pull the corresponding sequences now. \n",
    "\n",
    "First we concatenate all the proteomes together to make it easier to search the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folders containing proteomes\n",
    "MAG_PROT = paths_dict['ANALYSIS_DATA'][\"COASSEMBLY\"][\"MITO\"][\"MFANNOT\"][\"PROTEOMES\"]\n",
    "\n",
    "REF_PROT = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"REFS\"][\"MFANNOT\"]\n",
    "\n",
    "## Folder containing the blast dbs\n",
    "TO_ADD = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['TO_ADD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$MAG_PROT\" \"$REF_PROT\" \"$TO_ADD\" \n",
    "for i in \"$1\"/*fasta; do (cat \"${i}\"; echo) >> \"$3\"/all.fasta; done\n",
    "for i in \"$2\"/*fasta; do (cat \"${i}\"; echo) >> \"$3\"/all.fasta; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use [seqkit](https://github.com/shenwei356/seqkit) to pull out the sequences for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$WORKING_DATASET\" \"$TO_ADD\"\n",
    "\n",
    "for i in \"$1\"/*_toAdd.list; do\n",
    "    gene=$(basename $i | cut -f 1 -d '.')\n",
    "    seqkit grep -f $i \"$2\"/all.fasta > \"$1\"/\"$gene\".fasta\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put together the query and the extracted sequences (for only the 28 selected genes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE_SUBLIST = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['SUBMITOGENES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$GENE_SUBLIST\" \"$WORKING_DATASET\"\n",
    "\n",
    "cat $1 | while read line; do\n",
    "    cat \"$2\"/\"$line\".fasta \"$2\"/\"$line\"_toAdd.fasta > \"$2\"/\"$line\".all.fasta\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the trees, we probably need to format the fasta headers so that the tree inference programme is happy. That means replacing ';' and '.' with '-'. \n",
    "\n",
    "Finally we also use seqkit to rename any duplicates that may exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['CLEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$WORKING_DATASET\" \"$CLEAN\"\n",
    "\n",
    "for i in \"$1\"/*all.fasta; do\n",
    "    gene=$(basename $i | cut -f 1 -d '.')\n",
    "    cat $i | \\\n",
    "    tr ';' '_' | \\\n",
    "    sed -E 's/>(gene=.*_)(mag=.*)_(contig=.*)/>\\2_\\1\\3/' | \\\n",
    "    sed -E 's/>(gene=.*_)(accession=.*)_(contig=.*)/>\\2_\\1\\3/' | \\\n",
    "    seqkit rename \\\n",
    "    > \"$2\"/\"$gene\".fasta\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we rename the references we added to include a taxonomy string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$CLEAN\"\n",
    "\n",
    "for i in \"$1\"/*fasta\n",
    "    do cat $i | \\\n",
    "    sed -E 's/_gene/\\tgene/' | \\\n",
    "    seqkit replace -p '^(\\S+)(.+?)$' -r '{kv}$2' -k \"$1\"/taxonomy_string.tsv --keep-key | \\\n",
    "    tr '\\t' '_' \\\n",
    "    > tmp\n",
    "    mv tmp $i\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Align, trim, and infer single gene trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Align\n",
    "\n",
    "We align the genes with mafft-linsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gene_iterator import GeneIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with extracted gene dataset\n",
    "DATASET = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['CLEAN']\n",
    "\n",
    "# Read_genes\n",
    "GENE_SUBLIST = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['SUBMITOGENES']\n",
    "genes = set(line.split()[0].strip() for line in open(GENE_SUBLIST, \"r\"))\n",
    "\n",
    "# Directory for mafft output\n",
    "MAFFT_DIR = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES']['MAFFT']\n",
    "\n",
    "# Slurmlog csv\n",
    "SLURMLOG = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES']['MAFFTLOG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(DATASET, gene_list=genes, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.run_mafft(MAFFT_DIR, SLURMLOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2 Trim\n",
    "\n",
    "We do gentle trimming with TrimAl by removing columns with 80% or more gaps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing aligned fasta files\n",
    "MAFFT_DIR = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES']['MAFFT']\n",
    "\n",
    "# Read_genes\n",
    "GENE_SUBLIST = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['SUBMITOGENES']\n",
    "genes = set(line.split()[0].strip() for line in open(GENE_SUBLIST, \"r\"))\n",
    "\n",
    "# Directory for trimal output\n",
    "TRIMAL_DIR = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES']['TRIMAL']\n",
    "\n",
    "# Slurmlog csv\n",
    "SLURMLOG = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES']['TRIMALLOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(MAFFT_DIR, gene_list=genes, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.run_trimal(TRIMAL_DIR, SLURMLOG, MAFFT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3 Infer SGTs\n",
    "\n",
    "We infer trees with [IQ-TREE](http://www.iqtree.org/) using the best fitting model for each gene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing aligned, trimmed fasta files\n",
    "TRIMAL_DIR = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES']['TRIMAL']\n",
    "\n",
    "# Read_genes\n",
    "GENE_SUBLIST = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['SUBMITOGENES']\n",
    "genes = set(line.split()[0].strip() for line in open(GENE_SUBLIST, \"r\"))\n",
    "\n",
    "# Directory for trees output\n",
    "TREES_DIR = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES']['SGTS']\n",
    "\n",
    "# Slurmlog csv\n",
    "SLURMLOG = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES']['SGTLOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(TRIMAL_DIR, gene_list=genes, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.run_siqtree(TREES_DIR, SLURMLOG, TRIMAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I parsed the trees manually, and they looked mostly okay - just need to remove a couple of duplicates, which I did manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Preliminary concatenated phylogeny\n",
    "\n",
    "Now infer a preliminary concatenated phylogeny with the LG4X model. For the alignment, I don't realign the sequences but simply concatenate the trimmed files after removing duplicates. The tree will be used to do the final taxon sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for aligned and trimmed fasta files\n",
    "TRIMAL_DIR = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['CONCAT']['TRIMAL']\n",
    "\n",
    "## Output directory for fasta files\n",
    "PRELIM = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['CONCAT']['ALIGNMENTS']['PRELIM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First change the headers so that are the same across all genes for corresponding taxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TRIMAL_DIR\"\n",
    "\n",
    "for i in \"$1\"/*fasta; do \n",
    "    cat $i | sed -E 's/(>.*)_gene.*/\\1/' > tmp \n",
    "    mv tmp $i \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then concatenate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TRIMAL_DIR\" \"$PRELIM\"\n",
    "\n",
    "files=(\"$1\"/*fasta)\n",
    "\n",
    "perl /home/mahja/beta-Cyclocitral/src/cat_fasta.pl -f \"${files[@]}\" > \"$2\"/concat.fasta\n",
    "mv partitions.txt \"$2\"/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final concatenated alignment contains 121 taxa, 28 genes, and 8,401 alignment positions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output directory for tree\n",
    "TREE_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"TREE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PRELIM\" \"$TREE_DIR\"\n",
    "\n",
    "sbatch ../../uppmax_scripts/script_bin/job_iqtree.sh \"$1\"/concat.fasta \"$2\"/prelim/concat_121t_28g_LG4X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Concatenated tree\n",
    "\n",
    "### 6.1 Dataset\n",
    "We remove 16 taxa to reduce taxonomic redundancy and to get a small enough taxon sampling to make a figure for the main text. I also decided to remove Roombia truncata since it had low occupancy (9/28 genes), and did not cluster with K4 (based on BLAST results, K4 consistently blasted to cyrptophytes, while Roombia never did).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"DATASET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DATASET\"\n",
    "\n",
    "for i in \"$1\"/*.fasta; do seqkit grep -v -f \"$1\"/remove.list $i > tmp; mv tmp $i; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Align\n",
    "Align with mafft-ginsi (unalign = 0.6) as done for plastids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gene_iterator import GeneIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with extracted gene dataset\n",
    "DATASET = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"DATASET\"]\n",
    "\n",
    "# Read_genes\n",
    "GENE_SUBLIST = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['SUBMITOGENES']\n",
    "genes = set(line.split()[0].strip() for line in open(GENE_SUBLIST, \"r\"))\n",
    "\n",
    "# Directory for mafft output\n",
    "MAFFT_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"MAFFT\"]\n",
    "\n",
    "# Slurmlog csv\n",
    "SLURMLOG = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"MAFFTLOG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(DATASET, gene_list=genes, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.run_mafft(MAFFT_DIR, SLURMLOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Trim \n",
    "\n",
    "We do gentle trimming with BMGE by removing columns with 80% or more gaps, and using the BLOSUM30 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing aligned fasta files\n",
    "MAFFT_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"MAFFT\"]\n",
    "\n",
    "# Read_genes\n",
    "GENE_SUBLIST = paths_dict['ANALYSIS_DATA']['COASSEMBLY']['MITO']['TREES'][\"DATASET\"]['SUBMITOGENES']\n",
    "genes = set(line.split()[0].strip() for line in open(GENE_SUBLIST, \"r\"))\n",
    "\n",
    "# Directory for trimal output\n",
    "TRIMAL_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"TRIMAL\"]\n",
    "\n",
    "# Slurmlog csv\n",
    "SLURMLOG = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"TRIMALLOG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GeneIterator(MAFFT_DIR, gene_list=genes, suffix=\"fasta\")\n",
    "gi.unlock_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.run_bmge(TRIMAL_DIR, SLURMLOG, MAFFT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for aligned and trimmed fasta files\n",
    "TRIMAL_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"TRIMAL\"]\n",
    "\n",
    "## Output directory for fasta files\n",
    "CONCAT = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"ALIGNMENTS\"][\"CONCAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$TRIMAL_DIR\" \"$CONCAT\"\n",
    "\n",
    "files=(\"$1\"/*fasta)\n",
    "\n",
    "perl /home/mahja/beta-Cyclocitral/src/cat_fasta.pl -f \"${files[@]}\" > \"$2\"/concat_101t_28g_ginsi_bmge.fasta\n",
    "mv partitions.txt \"$2\"/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final alignment contains 101 taxa, 28 genes and 3,270 alignment sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Run ML and Bayesian phylogenetic analyses\n",
    "\n",
    "We run a tree with the LG+C60+G and CAT-GTR models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.5.1 Run tree with PhyloBayes\n",
    "\n",
    "Convert alignment to phylip format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$CONCAT\"\n",
    "\n",
    "perl ../../src/fasta2phylip.pl -f \"$1\"/concat_101t_28g_ginsi_bmge.fasta -o \"$1\"/concat_101t_28g_ginsi_bmge.phy\n",
    "\n",
    "cat \"$1\"/concat_101t_28g_ginsi_bmge.phy | tr '=' '_' > phylip\n",
    "mv phylip \"$1\"/concat_101t_28g_ginsi_bmge.phy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up 3 chains of phylobayes on noisy with the cat-gtr model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.5.2 Run tree with IQTREE\n",
    "\n",
    "We use the LG+C60+G model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output directory for tree\n",
    "TREE_DIR = paths_dict[\"ANALYSIS_DATA\"][\"COASSEMBLY\"][\"MITO\"][\"CONCAT\"][\"TREE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$CONCAT\" \"$TREE_DIR\"\n",
    "\n",
    "sbatch ../../uppmax_scripts/script_bin/job_iqtree.sh \"$1\"/mito-only-genes/concat_101t_28g_ginsi_bmge.fasta \"$2\"/mito-only-genes/concat_101t_28g_LG-C60-G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Lang, B. F., Beck, N., Prince, S., Sarrasin, M., Rioux, P., & Burger, G. (2023). Mitochondrial genome annotation with MFannot: a critical analysis of gene identification and gene model prediction. Frontiers in Plant Science, 14.\n",
    "\n",
    "Beck, N., Lang, B. F. (2010) MFannot, organelle genome annotation websever. Available at: https://github.com/BFL-lab/Mfannot.\n",
    "\n",
    "asn2gb tool from NCBI. Available at: https://ftp.ncbi.nlm.nih.gov/asn1-converters/by_program/asn2gb/ \n",
    "\n",
    "Williamson, K., Eme, L., Baños, H., McCarthy, C. G., Susko, E., Kamikawa, R., ... & Roger, A. J. (2025). A robustly rooted tree of eukaryotes reveals their excavate ancestry. Nature, 1-8.\n",
    "\n",
    "Kawachi, M., Nakayama, T., Kayama, M., Nomura, M., Miyashita, H., Bojo, O., ... & Kamikawa, R. (2021). Rappemonads are haptophyte phytoplankton. Current Biology, 31(11), 2395-2403.\n",
    "\n",
    "Wideman, J.G., Monier, A., Rodríguez-Martínez, R. et al. Unexpected mitochondrial genome diversity revealed by targeted single-cell genomics of heterotrophic flagellated protists. Nat Microbiol 5, 154–165 (2020). https://doi.org/10.1038/s41564-019-0605-4\n",
    "\n",
    "Nishimura, Y., Shiratori, T., Ishida, Ki. et al. Horizontally-acquired genetic elements in the mitochondrial genome of a centrohelid Marophrys sp. SRT127. Sci Rep 9, 4850 (2019). https://doi.org/10.1038/s41598-019-41238-6\n",
    "\n",
    "Yazaki, E., Yabuki, A., Nishimura, Y., Shiratori, T., Hashimoto, T., & Inagaki, Y. (2022). Microheliella maris possesses the most gene-rich mitochondrial genome in Diaphoretickes. Frontiers in Ecology and Evolution, 10, 1030570.\n",
    "\n",
    "Janouškovec, J., Tikhonenkov, D. V., Burki, F., Howe, A. T., Rohwer, F. L., Mylnikov, A. P., & Keeling, P. J. (2017). A new lineage of eukaryotes illuminates early mitochondrial genome reduction. Current Biology, 27(23), 3717-3724."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ptMAGs)",
   "language": "python",
   "name": "ptmags"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
